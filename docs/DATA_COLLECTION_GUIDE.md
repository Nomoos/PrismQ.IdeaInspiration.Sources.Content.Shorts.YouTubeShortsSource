# Data Collection Decision Guide

## Quick Start: Which Documentation Do I Need?

```
┌─────────────────────────────────────────────────────────┐
│  What do you want to know?                              │
└─────────────────────────────────────────────────────────┘
                         │
         ┌───────────────┼───────────────┐
         │               │               │
         ▼               ▼               ▼
    ┌─────────┐    ┌─────────┐    ┌─────────┐
    │ Quick   │    │ Detailed│    │ Visual  │
    │Overview │    │Analysis │    │ Diagram │
    └────┬────┘    └────┬────┘    └────┬────┘
         │              │              │
         ▼              ▼              ▼
  Summary.md     Analysis.md     Diagram.md
```

### 1. Quick Overview → [DATA_COLLECTION_SUMMARY.md](DATA_COLLECTION_SUMMARY.md)
**Best for:**
- Quick reference
- Understanding current capabilities
- Making decisions about what to collect
- Comparing API vs yt-dlp

**You'll learn:**
- ✅ What we collect now
- 🟢 What's easy to add
- 🟡 What's possible in future
- ❌ What's not accessible

### 2. Detailed Analysis → [DATA_COLLECTION_ANALYSIS.md](DATA_COLLECTION_ANALYSIS.md)
**Best for:**
- Comprehensive understanding
- Planning implementations
- Technical specifications
- API quota calculations

**You'll learn:**
- All available fields from YouTube API
- All available fields from yt-dlp
- Exact API costs and quota impact
- Storage considerations
- Implementation recommendations

### 3. Visual Diagrams → [DATA_COLLECTION_DIAGRAM.md](DATA_COLLECTION_DIAGRAM.md)
**Best for:**
- Visual learners
- System architecture overview
- Data flow understanding
- Priority matrix visualization

**You'll learn:**
- How data flows through the system
- Visual breakdown of all fields
- Priority matrix for additions
- Implementation roadmap

### 4. Complete Field Reference → [DATA_FIELDS_REFERENCE.md](DATA_FIELDS_REFERENCE.md)
**Best for:**
- Field-by-field lookup
- Implementation planning
- Database schema design
- API integration

**You'll learn:**
- Every single field available
- Collection method for each field
- Status (collected/easy/future/impossible)
- Organized by category

## Decision Trees

### "What Collection Method Should I Use?"

```
START: Need to collect YouTube Shorts data
  │
  └─> Use yt-dlp ⭐
      │
      ▼
  Comprehensive data collection:
  • Title, description, tags
  • Views, likes, comments
  • Subtitles (full text)
  • Quality metrics (resolution, FPS)
  • Channel info & analytics
  • No quota limits
```

**Result:**
- **Use yt-dlp** in 95% of cases
- **Use API** only for backward compatibility or specific one-off queries

### "What Additional Data Should I Collect?"

```
START: Want to add more data fields
  │
  ├─> What's your priority?
      │
      ├─> Need it NOW
      │   │
      │   └─> Go to "Quick Wins" ──────────────────────┐
      │                                                 │
      ├─> Need it SOON                                 │
      │   │                                             │
      │   └─> Go to "Medium Priority" ───────────────┐ │
      │                                               │ │
      └─> FUTURE planning                             │ │
          │                                           │ │
          └─> Go to "Future Enhancements" ─────────┐ │ │
                                                    │ │ │
                                                    ▼ ▼ ▼
Quick Wins (Week 1):                              ┌─────────┐
  • contentDetails flags (HD/SD, captions)        │ Choose  │
  • Hashtags from yt-dlp                          │  Phase  │
  • Channel verification                          └─────────┘
  • Thumbnail URLs                                     │
  Cost: FREE (already in responses)                    │
                                                       │
Medium Priority (Weeks 2-3):                           │
  • Status information (+2 quota/video)                │
  • Privacy, embeddable, made_for_kids                 │
  • Topic categories (+2 quota/video)                  │
  • Format details (codecs, bitrates)                  │
  Cost: +4 quota units per video                       │
                                                       │
Future Enhancements (Months):                          │
  • GPU visual analysis (faces, scenes, objects)       │
  • Audio analysis (music, speech quality)             │
  • NLP (sentiment, topics, clickbait)                 │
  • ML trend prediction                                │
  Cost: Development time + GPU processing              │
                                                       │
                                                       ▼
                                              Implement chosen phase
```

### "Is This Field Available?"

```
START: Want to collect specific field
  │
  ├─> Check field in DATA_FIELDS_REFERENCE.md
      │
      ├─> Status: ✅ Collected
      │   │
      │   └─> Already available! Check score_dictionary
      │
      ├─> Status: 🟢 Easy to add
      │   │
      │   ├─> Source: "Already in response"
      │   │   │
      │   │   └─> Can add without extra API cost ──┐
      │   │                                         │
      │   └─> Source: "yt-dlp"                     │
      │       │                                     │
      │       └─> Available, no quota cost ────────┤
      │                                             │
      ├─> Status: 🟡 Possible                       │
      │   │                                         │
      │   ├─> Requires extra API part (+quota)     │
      │   │   │                                     │
      │   │   └─> Calculate quota impact ──────────┤
      │   │                                         │
      │   └─> Requires GPU/ML processing           │
      │       │                                     │
      │       └─> Plan development effort ─────────┤
      │                                             │
      └─> Status: ❌ Not accessible                 │
          │                                         │
          └─> Find alternative approach             │
                                                    │
                                                    ▼
                                           Make informed decision
```

## Common Scenarios

### Scenario 1: "I want to build a trend predictor"

**Current Data Available:**
- ✅ Engagement metrics (views, likes, comments)
- ✅ Publishing date (calculate age)
- ✅ Views per day (velocity)
- ✅ Channel follower count
- ✅ Video quality metrics

**Easy Additions:**
- 🟢 Topic categories
- 🟢 Hashtags

**Future Enhancements:**
- 🟡 Visual analysis (thumbnails, scenes)
- 🟡 NLP sentiment analysis
- 🟡 ML-based viral probability

**Recommendation:** Start with current data + easy additions, build baseline model, then add ML features.

### Scenario 2: "I want to find story-based Shorts"

**Current Data Available:**
- ✅ Subtitles (full text from yt-dlp)
- ✅ Title and description
- ✅ Duration
- ✅ Tags

**Easy Additions:**
- 🟢 Hashtags (might include #story)

**Analysis Approach:**
1. Use subtitle text for keyword detection
2. Analyze title/description for story indicators
3. Check duration (stories usually 60-180 seconds)
4. Pattern matching on hashtags

**Recommendation:** Current data is sufficient. Use NLP on subtitles.

### Scenario 3: "I want to analyze content quality"

**Current Data Available:**
- ✅ Resolution (yt-dlp)
- ✅ FPS (yt-dlp)
- ✅ Aspect ratio (yt-dlp)
- ✅ Has subtitles
- ✅ Engagement rate

**Easy Additions:**
- 🟢 Video bitrate
- 🟢 Audio bitrate
- 🟢 Definition (HD/SD flag)

**Future Enhancements:**
- 🟡 Visual quality scoring (ML)
- 🟡 Audio quality analysis
- 🟡 Aesthetic scoring

**Recommendation:** Current + easy additions give good quality metrics. GPU analysis optional.

### Scenario 4: "I need to respect quota limits"

**Problem:** YouTube API has 10,000 units/day limit

**Solutions:**

1. **Switch to yt-dlp** ⭐ Best Solution
   - No quota limits
   - More data
   - Recommended for all new implementations

2. **Optimize API usage**
   - Current: 3 units/video = 3,333 videos/day
   - With status: 5 units/video = 2,000 videos/day
   - With status+topics: 7 units/video = 1,428 videos/day

3. **Hybrid approach**
   - Use yt-dlp for bulk collection
   - Use API for specific queries
   - Best of both worlds

**Recommendation:** Use yt-dlp for all collection. Keep API for backward compatibility only.

## Implementation Priority Matrix

```
┌──────────────────────────────────────────────────────────┐
│                  Priority Matrix                          │
├──────────────────────────────────────────────────────────┤
│                                                           │
│  High  │  P1: Do First      │  P2: Do Next               │
│ Value  │                    │                            │
│        │  • contentDetails  │  • Status info             │
│   ▲    │    flags          │  • Hashtags                │
│   │    │  • Channel        │  • Topic categories        │
│   │    │    verified       │                            │
│   │    │                   │                            │
│   │    ├───────────────────┼────────────────────────────┤
│   │    │  P3: If Time      │  P4: Skip                  │
│   │    │                   │                            │
│  Low   │  • Bitrate info   │  • Recording location      │
│ Value  │  • Music metadata │  • Localization            │
│        │                   │                            │
└────────┴───────────────────┴────────────────────────────┘
         Low Effort    ▶    High Effort

P1: Implement immediately (Week 1)
P2: Implement soon (Weeks 2-3)
P3: Implement if useful (Week 4+)
P4: Skip unless specifically needed
```

## Budget Calculator

### API Quota Usage

```
Current Setup:
  search().list:      100 units per search
  videos().list:        3 units per video
  Total per video:      3 units

With Quick Wins (FREE):
  videos().list:        3 units per video
  No change in quota!   ✅

With Status Info (+2):
  videos().list:        5 units per video
  Capacity: 2,000 videos/day

With Status + Topics (+4):
  videos().list:        7 units per video
  Capacity: 1,428 videos/day

yt-dlp:
  No quota limits!      ∞ videos per day ⭐
```

### Storage Estimation

```
Current (40 fields):
  Per idea:          2-5 KB
  100K ideas:      200-500 MB
  1M ideas:          2-5 GB

With All Additions (60+ fields):
  Per idea:          3-8 KB
  100K ideas:      300-800 MB
  1M ideas:          3-8 GB

SQLite can easily handle this! ✅
```

## FAQ

### Q: Should I use YouTube API or yt-dlp?

**A:** Use yt-dlp for 95% of cases.

**YouTube API provides:**
- ✅ Title, description, tags
- ✅ Views, likes, comments, favorites
- ✅ Channel info, upload date
- ❌ NO subtitles (text extraction)
- ❌ NO quality metrics (resolution, FPS)
- ❌ 10K quota/day limit

**yt-dlp provides:**
- ✅ All YouTube API fields PLUS
- ✅ Subtitles (full text extraction)
- ✅ Quality metrics (resolution, FPS, aspect ratio, codecs)
- ✅ Unlimited (no quota)
- ✅ Better for bulk collection

Use API only for:
- Backward compatibility
- Specific one-off queries
- When yt-dlp is not available

### Q: What fields should I add first?

**A:** Priority order:
1. contentDetails flags (HD, captions) - FREE
2. Channel verification - FREE
3. Hashtags - FREE
4. Status information - +2 quota/video
5. Topic categories - +2 quota/video

### Q: Can I get watch time and retention data?

**A:** No. These require channel ownership and are not available through any public API.

### Q: Can I get accurate dislike counts?

**A:** No. YouTube hid dislikes in December 2021. You might get some values from old videos, but they're unreliable.

### Q: How much will GPU analysis cost?

**A:** Development effort only. RTX 5090 hardware is already available. Processing time depends on:
- Video length
- Analysis complexity
- Batch size

Estimate: 1-5 seconds per video for basic CV analysis.

### Q: What about copyrighted music detection?

**A:** Not available through public APIs. You can:
- Detect if music is present (audio analysis)
- Extract music metadata if included (yt-dlp)
- Cannot detect Content ID matches

## Next Steps

1. **Read the appropriate documentation:**
   - Quick overview: [DATA_COLLECTION_SUMMARY.md](DATA_COLLECTION_SUMMARY.md)
   - Full analysis: [DATA_COLLECTION_ANALYSIS.md](DATA_COLLECTION_ANALYSIS.md)
   - Visual guide: [DATA_COLLECTION_DIAGRAM.md](DATA_COLLECTION_DIAGRAM.md)
   - Field reference: [DATA_FIELDS_REFERENCE.md](DATA_FIELDS_REFERENCE.md)

2. **Decide what to implement:**
   - Use Priority Matrix above
   - Consider quota impact
   - Check storage requirements

3. **Plan implementation:**
   - Phase 1: Quick wins (Week 1)
   - Phase 2: Status info (Week 2)
   - Phase 3: Enhanced metadata (Weeks 3-4)
   - Phase 4: Future enhancements (Months)

4. **Start coding:**
   - Update UniversalMetrics schema
   - Modify collection methods
   - Add tests
   - Deploy incrementally

## Support

For questions or issues:
- Check [Known Issues](../issues/KNOWN_ISSUES.md)
- Review [Project Roadmap](../issues/ROADMAP.md)
- Open a GitHub issue
- Refer to documentation

---

**Last Updated**: 2025-10-13  
**Current Version**: 1.0.0
